{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36e6b2b4",
   "metadata": {},
   "source": [
    "# Modelo de la turbina"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00d3107",
   "metadata": {},
   "source": [
    "## Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0e88c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aprendizaje por refuerzo\n",
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box\n",
    "from rl.agents import DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "\n",
    "#Red neuronal\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "#Arrays y operaciones aritméticas\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "\n",
    "#Aplicación web\n",
    "from werkzeug.wrappers import Request, Response\n",
    "from werkzeug.serving import run_simple\n",
    "from flask import Flask, render_template, request, redirect, url_for, flash\n",
    "from wtforms import Form, FloatField, validators\n",
    "\n",
    "#Gráficos e impresión por pantalla\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from matplotlib.figure import Figure\n",
    "import base64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e256b224",
   "metadata": {},
   "source": [
    "## Entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3727341e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindmillEnv(Env):\n",
    "    def __init__(self, pRef):\n",
    "        \n",
    "        #Número de acciones\n",
    "        self.action_space = Discrete(7)\n",
    "        \n",
    "        #Espacio de observación\n",
    "        self.observation_space = Box(low=np.array([5]), high=np.array([14]))\n",
    "        \n",
    "        #Tiempo de entrenamiento\n",
    "        self.training_length = 1000\n",
    "        \n",
    "        #Parámetros de la turbina\n",
    "        #Variables estáticas\n",
    "        self.wind_density = 1.225\n",
    "        self.radious = 2\n",
    "        self.wind = 10.0\n",
    "        self.powerRef = pRef\n",
    "        \n",
    "        #Variables dinámicas\n",
    "        self.angle = random.uniform(5.0, 14.0)\n",
    "        self.power_eficiency = (-0.0422)*self.angle + 0.5911\n",
    "        self.genPowerEuler = 0.5*self.wind_density*math.pi*pow(self.radious, 2)*pow(self.wind, 3)*self.power_eficiency\n",
    "        self.error = abs(self.powerRef - self.genPowerEuler)\n",
    "    \n",
    "    \n",
    "    def step(self, action):\n",
    "        \n",
    "        powerRefCheck = env.powerRef\n",
    "        \n",
    "        #Guardamos el error del paso anterior\n",
    "        last_error = self.error\n",
    "        \n",
    "        #Reducimos el tiempo de entrenamiento en 1 segundo\n",
    "        self.training_length -= 1\n",
    "        \n",
    "        #Aplicamos la acción\n",
    "        self.angle += (action/10.0) - 0.01\n",
    "         \n",
    "        #Linealizamos el modelo de la turbina\n",
    "        for t in range(1, 151):\n",
    "            self.power_eficiency = (-0.0422)*self.angle + 0.5911\n",
    "            self.genPowerEuler += ((0.5*self.wind_density*math.pi*pow(self.radious, 2)*pow(self.wind, 3)\n",
    "                                    *self.power_eficiency)/5 - self.genPowerEuler/5)*0.5\n",
    "        \n",
    "        #Calculamos el error actual\n",
    "        self.error = abs(powerRefCheck - self.genPowerEuler)\n",
    "        \n",
    "        \n",
    "        #Calculamos la recompensa\n",
    "        if self.error < last_error:\n",
    "            reward = 1 - (self.error/10)\n",
    "        if self.error > last_error:\n",
    "            reward = -100 - (self.error/10)\n",
    "        else:\n",
    "            reward = -50 - (self.error/10)\n",
    "            \n",
    "        #Comprobamos si el tiempo de entrenamiento ha llegado a 0\n",
    "        if self.training_length <= 0:\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "                \n",
    "        #Info\n",
    "        info = {}\n",
    "        \n",
    "        return self.angle, reward, done, info\n",
    "    \n",
    "    #Función para resetear los parámetros dinámicos\n",
    "    def reset(self):\n",
    "        \n",
    "        self.angle = random.uniform(5, 14)\n",
    "        self.power_eficiency = (-0.0422)*self.angle + 0.5911\n",
    "        self.genPowerEuler = 0.5*self.wind_density*math.pi*pow(self.radious, 2)*pow(self.wind, 3)*self.power_eficiency\n",
    "        self.error = abs(self.powerRef - self.genPowerEuler)\n",
    "        \n",
    "        self.training_length = 1000\n",
    "        \n",
    "        return self.angle\n",
    "    \n",
    "    \n",
    "    #GETTERS Y SETTERS\n",
    "    #Potencia de referencia\n",
    "    @property\n",
    "    def powerRefMethod(self):\n",
    "        return self.powerRef\n",
    "    \n",
    "    @powerRefMethod.setter\n",
    "    def powerRefMethod(self, powerRefv):\n",
    "        self.powerRef = powerRefv\n",
    "    \n",
    "    \n",
    "    #Potencia generada\n",
    "    @property\n",
    "    def genPowerEulerMethod(self):\n",
    "        return self.genPowerEuler\n",
    "    \n",
    "    @genPowerEulerMethod.setter\n",
    "    def genPowerEulerMethod(self, genPowerEulerv):\n",
    "        self.genPowerEuler = genPowerEulerv\n",
    "    \n",
    "    \n",
    "    #Ángulo\n",
    "    @property\n",
    "    def angleMethod(self):\n",
    "        return self.angle\n",
    "    \n",
    "    @angleMethod.setter\n",
    "    def angleMethod(self, anglev):\n",
    "        self.angle = anglev\n",
    "    \n",
    "    \n",
    "    #Tiempo de entrenamiento\n",
    "    @property\n",
    "    def training_lengthMethod(self):\n",
    "        return self.training_length\n",
    "    \n",
    "    @training_lengthMethod.setter\n",
    "    def training_lengthMethod(self, training_lengthv):\n",
    "        self.training_length = training_lengthv\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfbde0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el entorno en una variable\n",
    "env = WindmillEnv(1000)\n",
    "states = env.observation_space.shape\n",
    "actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bee5b5",
   "metadata": {},
   "source": [
    "## Red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf1b938",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para crer el modelo de la red neuronal\n",
    "def build_model(states, actions):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_shape = states))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(actions, activation='linear'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2b9fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(states, actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46ec16f",
   "metadata": {},
   "source": [
    "## Agente DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fd3e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para crear el agente\n",
    "def build_agent(model, actions):\n",
    "    memory = SequentialMemory(limit=30000, window_length=1)\n",
    "    dqn = DQNAgent(model=model, memory=memory, policy=BoltzmannQPolicy(), nb_actions=actions, nb_steps_warmup=1000)\n",
    "    return dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48d1313",
   "metadata": {},
   "outputs": [],
   "source": [
    "lastExecution_powerR = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9db393",
   "metadata": {},
   "source": [
    "## Ejecución de la interfaz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e274f953",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "class InputForm(Form):\n",
    "    #Variable para recoger el valor de la potencia introducida\n",
    "    r = FloatField(validators=[validators.InputRequired()])\n",
    "\n",
    "@app.route(\"/\", methods=[\"POST\", \"GET\"])\n",
    "def mainFunction():\n",
    "    \n",
    "    form = InputForm(request.form)\n",
    "    \n",
    "    if request.method == \"POST\":\n",
    "        #Comprobación de seguridad\n",
    "        if (isinstance(form.r.data, (int, float)) is not True) or (form.r.data > 2950.0) or (form.r.data < 100.0):\n",
    "            flash('El valor introducido debe ser un número entre 100 y 2900.')\n",
    "            return render_template(\"RL.html\", form=form)\n",
    "        \n",
    "        global lastExecution_powerR\n",
    "        global dqn\n",
    "        \n",
    "        powerR = form.r.data\n",
    "        env.powerRefMethod = powerR\n",
    "        \n",
    "        #Comprobación para no entrenar dos veces seguidas el modelo para la misma potencia\n",
    "        if (request.form['submit_button'] == 'Entrenado') and (powerR != lastExecution_powerR):\n",
    "            #Entrenamiento del agente\n",
    "            dqn = build_agent(model, actions)\n",
    "            dqn.compile(Adam(learning_rate=1e-3), metrics=['mae'])\n",
    "            dqn.fit(env, nb_steps=30000, visualize=False, verbose=1)   \n",
    "            lastExecution_powerR = powerR\n",
    "        \n",
    "        #Reseteamos las variables del entorno\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        score = 0\n",
    "        \n",
    "        powerArray = []\n",
    "        anglesArray = []\n",
    "        initPower = env.genPowerEulerMethod\n",
    "        #Se ha aumentado el tiempo de entrenamiento para dar mas margen al modelo\n",
    "        env.training_lengthMethod = 2000\n",
    "        powerArray.append(env.genPowerEulerMethod)\n",
    "        anglesArray.append(env.angleMethod)\n",
    "    \n",
    "        while not done:\n",
    "            #Dependiendo del botón pulsado, las acciones son aleatorias o las toma el modelo entrenado\n",
    "            if request.form['submit_button'] == 'Sin entrenar':\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action = dqn.forward(obs)\n",
    "                    \n",
    "            obs, reward, done, info = env.step(action)\n",
    "            score += reward\n",
    "        \n",
    "            powerArray.append(env.genPowerEulerMethod)\n",
    "            anglesArray.append(env.angleMethod)\n",
    "            \n",
    "            #Condición de parada para un error menor a 2Kw\n",
    "            if abs(env.powerRefMethod - env.genPowerEulerMethod) < 2.0:\n",
    "                break\n",
    "        \n",
    "        #Gráficas con los resultados de la ejecución\n",
    "        figure = Figure()\n",
    "        figure.set_size_inches(18.5, 10.5)\n",
    "\n",
    "        plt1 = figure.add_subplot(1,2,1)\n",
    "        plt1.set_title(\"Potencia generada\")\n",
    "        plt1.axhline(y=powerR, color='r', linestyle='-')\n",
    "        plt1.set_xlabel(\"Pasos\")\n",
    "        plt1.set_ylabel(\"Potencia\")\n",
    "        plt1.plot(powerArray, 'b')\n",
    "        \n",
    "        plt2 = figure.add_subplot(1,2,2)\n",
    "        plt2.set_title(\"Ángulo del aspa\")\n",
    "        plt2.set_xlabel(\"Pasos\")\n",
    "        plt2.set_ylabel(\"Ángulo\")\n",
    "        plt2.plot(anglesArray, 'g')\n",
    "        \n",
    "        output = io.BytesIO()\n",
    "        figure.savefig(output, format='png')\n",
    "        plotData = base64.b64encode(output.getbuffer()).decode(\"ascii\")\n",
    "        \n",
    "        return render_template(\"RL.html\", form=form, plotImg=plotData, finalPower=env.genPowerEulerMethod, initPower=initPower, finalAngle=env.angleMethod)\n",
    "    else:\n",
    "        \n",
    "        return render_template(\"RL.html\", form=form)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.secret_key=\"anystringhere\"\n",
    "    run_simple('localhost', 8000, app)\n",
    "    \n",
    "lastExecution_powerR = 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
