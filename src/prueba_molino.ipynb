{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e00d3107",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0e88c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RL libraries\n",
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box\n",
    "from rl.agents import DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "\n",
    "#Neural network libraries\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "#Math libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "\n",
    "#Web server libraries\n",
    "from werkzeug.wrappers import Request, Response\n",
    "from werkzeug.serving import run_simple\n",
    "from flask import Flask, render_template, request, redirect, url_for, flash\n",
    "from wtforms import Form, FloatField, validators\n",
    "\n",
    "#Visual libraries\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from matplotlib.figure import Figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e256b224",
   "metadata": {},
   "source": [
    "# Enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3727341e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindmillEnv(Env):\n",
    "    def __init__(self, pRef):\n",
    "        \n",
    "        #Set action space\n",
    "        self.action_space = Discrete(8)\n",
    "        \n",
    "        #Set observation space\n",
    "        self.observation_space = Box(low=np.array([5]), high=np.array([14]))\n",
    "        \n",
    "        #Set training time\n",
    "        self.training_length = 90\n",
    "        self.oposite_training_length = 90\n",
    "        \n",
    "        #SET WINDMILL PARAMETERS\n",
    "        #Static parameters\n",
    "        self.wind_density = 1.225\n",
    "        self.radious = 2\n",
    "        self.wind = 10.0\n",
    "        self.powerRef = pRef\n",
    "        \n",
    "        #Dynamic parameters\n",
    "        self.angle = random.uniform(5.0, 14.0)\n",
    "        self.power_eficiency = -0.0422*self.angle + 0.5911\n",
    "        self.genPowerEuler = 0.5*self.wind_density*math.pi*pow(self.radious, 2)*pow(self.wind, 3)*self.power_eficiency\n",
    "        self.error = abs(self.powerRef - self.genPowerEuler)\n",
    "        \n",
    "    def step(self, action):\n",
    "        #Save the error from the previous step in a variable\n",
    "        last_error = self.error\n",
    "        \n",
    "        #Reduces training time in 1 second\n",
    "        self.training_length -= 1\n",
    "        \n",
    "        #Apply action\n",
    "            #0.0 - 0.1 = -0.1 (angle reduces in 0.1)\n",
    "            #0.1 - 0.1 = 0.0 (angle does not change)\n",
    "            #0.2 - 0.1 = 0.1 (angle increases in 0.1)\n",
    "        #self.angle += (action/10.0) - 0.1\n",
    "        if action == 0:\n",
    "            self.angle += 0\n",
    "        elif action == 1:\n",
    "            self.angle += 1\n",
    "        elif action == 2:\n",
    "            self.angle -= 1\n",
    "        elif action == 3:\n",
    "            self.angle += 0.1\n",
    "        elif action == 4:\n",
    "            self.angle -= 0.1\n",
    "        elif action == 5:\n",
    "            self.angle += 0.01\n",
    "        elif action == 6:\n",
    "            self.angle -= 0.01\n",
    "        \n",
    "        #Euler for Calculating energy\n",
    "        for t in range(1, 151):\n",
    "            self.power_eficiency = -0.0422*self.angle + 0.5911\n",
    "            self.genPowerEuler += ((0.5*self.wind_density*math.pi*pow(self.radious, 2)*pow(self.wind, 3)\n",
    "                                    *self.power_eficiency)/5 - self.genPowerEuler/5)*0.5\n",
    "        \n",
    "        #Calculates final error\n",
    "        self.error = abs(self.powerRefMethod - self.genPowerEuler)\n",
    "        \n",
    "        #Calculates reward\n",
    "        if self.error < last_error:\n",
    "            reward = 1 - (self.error/100)\n",
    "        elif self.error == last_error:\n",
    "            reward = -1 - (self.error/100)\n",
    "        else:\n",
    "            reward = -100 - (self.error/100)\n",
    "        \n",
    "        #Check if the training finished\n",
    "        if self.training_length <= 0:\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "                \n",
    "        #placeholder for the info\n",
    "        info = {}\n",
    "        \n",
    "        #Return step information\n",
    "        return self.angle, reward, done, info\n",
    "    \n",
    "    def reset(self):\n",
    "        #Reset parameters\n",
    "        self.angle = random.uniform(5, 14)\n",
    "        self.wind = 10.0\n",
    "        self.power_eficiency = -0.0422*self.angle + 0.5911\n",
    "        self.genPowerEuler = 0.5*self.wind_density*math.pi*pow(self.radious, 2)*pow(self.wind, 3)*self.power_eficiency\n",
    "        self.error = abs(self.powerRef - self.genPowerEuler)\n",
    "        \n",
    "        #Reset training time\n",
    "        self.training_length = 90\n",
    "        \n",
    "        return self.angle\n",
    "    \n",
    "    #PowerRef\n",
    "    @property\n",
    "    def powerRefMethod(self):\n",
    "        return self.powerRef\n",
    "    \n",
    "    @powerRefMethod.setter\n",
    "    def powerRefMethod(self, powerRefv):\n",
    "        self.powerRef = powerRefv\n",
    "        \n",
    "    #PowerGen\n",
    "    @property\n",
    "    def genPowerEulerMethod(self):\n",
    "        return self.genPowerEuler\n",
    "    \n",
    "    @genPowerEulerMethod.setter\n",
    "    def genPowerEulerMethod(self, genPowerEulerv):\n",
    "        self.genPowerEuler = genPowerEulerv\n",
    "    \n",
    "    #Angle\n",
    "    @property\n",
    "    def angleMethod(self):\n",
    "        return self.angle\n",
    "    \n",
    "    @angleMethod.setter\n",
    "    def angleMethod(self, anglev):\n",
    "        self.angle = anglev\n",
    "    \n",
    "    #Training length\n",
    "    @property\n",
    "    def training_lengthMethod(self):\n",
    "        return self.training_length\n",
    "    \n",
    "    @training_lengthMethod.setter\n",
    "    def training_lengthMethod(self, training_lengthv):\n",
    "        self.training_length = training_lengthv\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0069fb",
   "metadata": {},
   "source": [
    "# DQN Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfbde0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = WindmillEnv(2000)\n",
    "states = env.observation_space.shape\n",
    "actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf1b938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(states, actions):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_shape = states))\n",
    "    model.add(Dense(28, activation='relu'))\n",
    "    model.add(Dense(actions, activation='linear'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2b9fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(states, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fd3e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_agent(model, actions):\n",
    "    memory = SequentialMemory(limit=50000, window_length=1)\n",
    "    dqn = DQNAgent(model=model, memory=memory, policy=BoltzmannQPolicy(), nb_actions=actions, nb_steps_warmup=1000)\n",
    "    return dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18dcf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lastExecution_powerR = 0\n",
    "dqn = build_agent(model, actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9db393",
   "metadata": {},
   "source": [
    "# Traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a022180",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dqn.compile(Adam(learning_rate=1e-3), metrics=['mae'])\n",
    "#dqn.fit(env, nb_steps=8000, visualize=False, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16bd0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "class InputForm(Form):\n",
    "    r = FloatField(validators=[validators.InputRequired()])\n",
    "\n",
    "@app.route(\"/\", methods=[\"POST\", \"GET\"])\n",
    "def mainFunction():\n",
    "    \n",
    "    form = InputForm(request.form)\n",
    "    \n",
    "    if request.method == \"POST\":\n",
    "        \n",
    "        if isinstance(form.r.data, (int, float)) is not True:\n",
    "            flash('El valor introducido debe ser un nÃºmero.')\n",
    "            return render_template(\"RL.html\", form=form)\n",
    "        \n",
    "        powerArray = []\n",
    "        anglesArray = []\n",
    "        global lastExecution_powerR\n",
    "        global dqn\n",
    "        powerR = form.r.data\n",
    "        episodes = 1\n",
    "        env = WindmillEnv(powerR)\n",
    "\n",
    "        if request.form['submit_button'] == 'trained':\n",
    "            if powerR != lastExecution_powerR:\n",
    "                dqn = build_agent(model, actions)\n",
    "                dqn.compile(Adam(learning_rate=1e-3), metrics=['mae'])\n",
    "                dqn.fit(env, nb_steps=10000, visualize=False, verbose=1)\n",
    "                lastExecution_powerR = powerR\n",
    "            \n",
    "        for episode in range(1, episodes+1):\n",
    "            obs = env.reset()\n",
    "            done = False\n",
    "            score = 0\n",
    "            env.training_lengthMethod = 2000\n",
    "            #env.training_lengthMethod(2000)\n",
    "    \n",
    "            powerArray.append(env.genPowerEulerMethod)\n",
    "            anglesArray.append(env.angle)\n",
    "    \n",
    "            while not done:\n",
    "                if request.form['submit_button'] == 'non-trained':\n",
    "                    action = env.action_space.sample()\n",
    "                else:\n",
    "                    action = dqn.forward(obs)\n",
    "                    \n",
    "                obs, reward, done, info = env.step(action)\n",
    "                score += reward\n",
    "        \n",
    "                powerArray.append(env.genPowerEulerMethod)\n",
    "                anglesArray.append(env.angle)\n",
    "        \n",
    "                #if env.error <= 33.0:\n",
    "                #    break\n",
    "        \n",
    "        figure = Figure()\n",
    "        plt = figure.add_subplot(1,1,1)\n",
    "        xs = range(90)\n",
    "        plt.axhline(y=env.powerRefMethod, color='r', linestyle='-')\n",
    "        plt.set_xlabel(\"steps\")\n",
    "        plt.set_ylabel(\"power\")\n",
    "        plt.plot(powerArray, 'b')\n",
    "        output = io.BytesIO()\n",
    "        FigureCanvas(figure).print_png(output)\n",
    "        return Response(output.getvalue(), mimetype='image/png')\n",
    "\n",
    "    else:\n",
    "        \n",
    "        return render_template(\"RL.html\", form=form)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.secret_key=\"anystringhere\"\n",
    "    run_simple('localhost', 8000, app)\n",
    "    \n",
    "lastExecution_powerR = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdad5797",
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = 10\n",
    "powerArray = []\n",
    "anglesArray = []\n",
    "powerRefArray = []\n",
    "env = WindmillEnv(2000)\n",
    "\n",
    "for episode in range(1, episodes+1):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "    refPower = env.powerRefMethod\n",
    "    #env.training_lengthMethod = 2000\n",
    "    initTrainingLenght = env.training_lengthMethod\n",
    "    \n",
    "    powerArray.append(env.genPowerEulerMethod)\n",
    "    anglesArray.append(env.angleMethod)\n",
    "    powerRefArray.append(env.powerRefMethod)\n",
    "    \n",
    "    while not done:\n",
    "        action = dqn.forward(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "        \n",
    "        if env.training_lengthMethod % 200 == 0:\n",
    "            #env.genPowerEulerMethod += random.uniform(-300.0,300.0)\n",
    "            #env.powerRefMethod = refPower = env.powerRef + random.uniform(-300.0,300.0)\n",
    "            #env.angleMethod += random.uniform(-0.5,0.5)\n",
    "            \n",
    "        powerArray.append(env.genPowerEulerMethod)\n",
    "        anglesArray.append(env.angleMethod)\n",
    "        powerRefArray.append(env.powerRefMethod)\n",
    "        \n",
    "        #if env.error <= 16.0:\n",
    "        #    break\n",
    "        \n",
    "    print('Episode:{} Score:{} Steps:{} Power:{}'.format(episode, score, initTrainingLenght - env.training_lengthMethod, env.genPowerEulerMethod))\n",
    "    \n",
    "plt.title(\"Trained model with changes in reference power\")\n",
    "plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"power\")\n",
    "plt.plot(powerRefArray, 'r')\n",
    "plt.plot(powerArray, 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6ad2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn = build_agent(model, actions)\n",
    "dqn.compile(Adam(learning_rate=1e-3), metrics=['mae'])\n",
    "dqn.fit(env, nb_steps=5000, visualize=False, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2014ecd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.fit(env, nb_steps=30000, visualize=False, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b33b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = 1\n",
    "\n",
    "for episode in range(1, episodes+1):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "    powerArray = []\n",
    "    anglesArray = []\n",
    "    powerRefArray = []\n",
    "    refPower = env.powerRef\n",
    "    env.training_length = 2000\n",
    "    env.oposite_training_length = 2000\n",
    "    initTrainingLenght = env.training_length\n",
    "    \n",
    "    powerArray.append(env.genPowerEuler)\n",
    "    anglesArray.append(env.angle)\n",
    "    \n",
    "    while not done:\n",
    "        action = dqn.forward(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "        print(env.error)\n",
    "        \n",
    "        #if env.training_length % 20 == 0:\n",
    "        #    env.wind += random.uniform(-0.5,0.5)\n",
    "        \n",
    "        powerArray.append(env.genPowerEuler)\n",
    "        anglesArray.append(env.angle)\n",
    "        \n",
    "    print('Episode:{} Score:{} Steps:{} Power:{}'.format(episode, score, initTrainingLenght \n",
    "                                                         - env.training_length, env.genPowerEuler))\n",
    "    \n",
    "    plt.title(\"Power\")#, plt.axhline(y=refPower, color='r', linestyle='-')\n",
    "    plt.plot(powerArray, 'b')\n",
    "    plt.plot(powerRefArray, 'r')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.title(\"Angle\"), plt.plot(anglesArray)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c145913",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8adb42b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
